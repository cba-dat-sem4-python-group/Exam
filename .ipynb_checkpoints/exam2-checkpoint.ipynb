{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import operator\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Card:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.contour = []    #card contour\n",
    "        self.width = 0       #contour max width?\n",
    "        self.height = 0      #contour max height?\n",
    "        self.center = []\n",
    "        self.coords = []     #the rects 4 corners\n",
    "        self.warped = []     #warped img of the card\n",
    "        self.warped_thresh = []\n",
    "        \n",
    "        self.num_img = []\n",
    "        self.suit_img = []\n",
    "        \n",
    "        self.num = None\n",
    "        self.suit = None\n",
    "        \n",
    "    def draw_warped(self):\n",
    "        cv2.imshow(self.num+self.suit+str(self.height)+str(self.width), self.warped)\n",
    "        \n",
    "    def draw_card_outlines(self, img):\n",
    "        cv2.polylines(img, np.array([self.coords]), True, (0,255,255), 2)\n",
    "        \n",
    "    def draw_suit(self):\n",
    "        cv2.imshow(str(np.sum(self.suit_img)), self.suit_img)\n",
    "        \n",
    "    def draw_num(self):\n",
    "        cv2.imshow(str(np.sum(self.num_img)), self.num_img)\n",
    "        \n",
    "    def draw_text(self, img):\n",
    "    \n",
    "        suit_text = [\"Hearts\", \"Spades\", \"Diamonds\", \"Clubs\"]\n",
    "        num_text = ['Ace','Two','Three','Four','Five','Six','Seven','Eight','Nine','Ten','Jack','Queen','King']\n",
    "    \n",
    "        FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        TEXT = num_text[self.num-1] + \" \" + suit_text[self.suit]\n",
    "        FONT_SIZE = 0.8\n",
    "        FONT_COLOR = (0, 255, 0)\n",
    "        THICKNESS = 2\n",
    "        \n",
    "        ######\n",
    "        \n",
    "        # get boundary of this text\n",
    "        textsize = cv2.getTextSize(TEXT, FONT, FONT_SIZE, THICKNESS)[0]\n",
    "\n",
    "        # get coords based on boundary\n",
    "        text_x = int(self.center[0] - (textsize[0]/2))\n",
    "        text_y = int(self.center[1] + (textsize[1]/2))\n",
    "        \n",
    "        text_y = text_y - int(self.height/2) - 25\n",
    "        \n",
    "        \n",
    "        # Add text centered on image\n",
    "        cv2.putText(img, TEXT, (text_x, text_y), FONT, FONT_SIZE, FONT_COLOR, thickness=THICKNESS)\n",
    "    \n",
    "    def set_center(self):\n",
    "        \n",
    "        # Adds x's together & y's together and takes the avg\n",
    "        pts_sum = np.sum(self.coords, axis=0)/len(self.coords)\n",
    "        \n",
    "        # Lav til int fordi vi ikke kan lande mellem 2 pixels\n",
    "        x = int(pts_sum[0])\n",
    "        y = int(pts_sum[1])\n",
    "        \n",
    "        self.center = [x, y]\n",
    "        \n",
    "        \n",
    "    def find_warped_card(self, img):\n",
    "        \n",
    "        order_rect = lambda p: math.atan2(p[1]-self.center[1], p[0]-self.center[0])\n",
    "        \n",
    "        self.coords = sorted(self.coords, key=order_rect)\n",
    "        \n",
    "        w, h = 200, 300 # width, height\n",
    "\n",
    "        # lav firkant i det format vi vil warp til\n",
    "        dst = np.array([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]], dtype = \"float32\")\n",
    "        \n",
    "        ###################################\n",
    "\n",
    "        # Lav første firkant ud fra self.coords og konverter til float\n",
    "        rect1 = np.array(self.coords, dtype = \"float32\").reshape((4,2))\n",
    "        \n",
    "        # Compute the perspective transformation matrix\n",
    "        transformation_matrix = cv2.getPerspectiveTransform(rect1, dst)\n",
    "        \n",
    "        # Lav første warp\n",
    "        warp1 = cv2.warpPerspective(img, transformation_matrix, (w, h))\n",
    "        \n",
    "        ###################################\n",
    "        \n",
    "        # Anden firkant er samme firkant som før bare startende fra et nabo-punkt\n",
    "        rect2 = np.array(self.coords[1:] + [self.coords[0]], dtype = \"float32\").reshape((4,2))\n",
    "        \n",
    "        # Compute the perspective transformation matrix\n",
    "        transformation_matrix = cv2.getPerspectiveTransform(rect2, dst)\n",
    "        \n",
    "        # Lav anden warp\n",
    "        warp2 = cv2.warpPerspective(img, transformation_matrix, (w, h))\n",
    "        \n",
    "        ####################################\n",
    "        \n",
    "        # Sæt self.warped til den warp som har den mindste værdi i det øverste venstre hjørne.\n",
    "        # Den warp der har mindst hvidt (og derfor lavest værdi) burde være den, der vender den tigtige vej.\n",
    "        self.warped = min(warp1, warp2, key=lambda x: np.sum(x[12:75, 9:39]))\n",
    "        \n",
    "        \n",
    "    def find_icons(self):\n",
    "        \n",
    "        # FOUND BY SLAVE LABOR\n",
    "        CORNER_WIDTH = 48\n",
    "        CORNER_HEIGHT = 140\n",
    "        \n",
    "        # Taken from comparison imgs\n",
    "        NUM_WIDTH = 70\n",
    "        NUM_HEIGHT = 125\n",
    "        SUIT_WIDTH = 70\n",
    "        SUIT_HEIGHT = 100\n",
    "\n",
    "        #####\n",
    "        \n",
    "        # 1.Cut corner out 2. Make it bigger 3. Make it grayscale\n",
    "        corner = self.warped[0:CORNER_HEIGHT, 0:CORNER_WIDTH]\n",
    "        corner_big = cv2.resize(corner, (0,0), fx=3, fy=3)\n",
    "        corner_big_gray = cv2.cvtColor(corner_big, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "\n",
    "        # Make it black & white and more crisp\n",
    "        thresh = cv2.threshold(corner_big_gray, 180, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "        #thresh = cv2.adaptiveThreshold(corner_big_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 333, 1)\n",
    "        \n",
    "        self.warped_thresh = thresh\n",
    "        \n",
    "        # Divide img into number & suit\n",
    "        num  = thresh[0:255, 0:144]\n",
    "        suit = thresh[256:420, 0:144]\n",
    "        \n",
    "        self.num_img  = self.crop_and_resize_icon(num, NUM_WIDTH, NUM_HEIGHT)\n",
    "        self.suit_img = self.crop_and_resize_icon(suit, SUIT_WIDTH, SUIT_HEIGHT)\n",
    "        \n",
    "        self.find_num()  # find numerisk værdi fra icon\n",
    "        self.find_suit() # find numerisk værdi fra icon\n",
    "        \n",
    "    def crop_and_resize_icon(self, img, new_width, new_height):\n",
    "    \n",
    "        #find contours\n",
    "        contours = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "        # Check om der blev fundet noget icon\n",
    "        if(len(contours) == 0): return \n",
    "\n",
    "        # Find det icon med det største areal\n",
    "        icon = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Find afgrænsende firkant\n",
    "        x, y, w, h = cv2.boundingRect(icon)\n",
    "\n",
    "        # Crop icon\n",
    "        rect = img[y:y+h, x:x+w]\n",
    "\n",
    "        #return resized icon\n",
    "        return cv2.resize(rect, (new_width, new_height), 0, 0)\n",
    "    \n",
    "    def find_num(self):\n",
    "        \n",
    "        # lav et dict med key=filnavn og value=img\n",
    "        num_img_dict = {x: cv2.imread(\"./test_cards/\"+str(x)+\".jpg\", cv2.IMREAD_GRAYSCALE) for x in range(1,14)}\n",
    "        \n",
    "        # lav nyt dict med key=filnavn og value=absdiff (jo mindre et tal jo bedre et match)\n",
    "        best_match_dict = {k: np.sum(cv2.absdiff(self.num_img, v)) for k, v in num_img_dict.items()}\n",
    "        \n",
    "        # sætter self.num til det bedste match\n",
    "        self.num = min(best_match_dict, key=best_match_dict.get)\n",
    "\n",
    "        \n",
    "    def find_suit(self):\n",
    "        \n",
    "        suits = [\"h\", \"s\", \"d\", \"c\"]\n",
    "        \n",
    "        # lav et dict med key=filnavn og value=img\n",
    "        suit_img_dict = {x:cv2.imread(\"./test_cards/\"+x+\".jpg\", cv2.IMREAD_GRAYSCALE) for x in suits}\n",
    "\n",
    "        # lav nyt dict med key=filnavn og value=absdiff (jo mindre et tal jo bedre et match)\n",
    "        best_match_dict = {k: np.sum(cv2.absdiff(self.suit_img, v)) for k, v in suit_img_dict.items()}\n",
    "        \n",
    "        # sætter self.suit til det bedste match\n",
    "        self.suit = suits.index(min(best_match_dict, key=best_match_dict.get))\n",
    "        \n",
    "        \n",
    "    def validate(self): return self.num is not None and self.suit is not None\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cards(og_frame, pp_frame):\n",
    "    \n",
    "    #List holding valid cards\n",
    "    found_cards = []\n",
    "    \n",
    "    #Find all contours from given frame\n",
    "    contours = cv2.findContours(pp_frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    \n",
    "    #Go through each contour as c\n",
    "    for c in contours:\n",
    "        \n",
    "        size = cv2.contourArea(c)                       # areal\n",
    "        peri = cv2.arcLength(c, True)                   # omkreds\n",
    "        approx = cv2.approxPolyDP(c, 0.01*peri, True)   # reducere antal hjørner -> prøv at sæt den op til 0.05 (var 0.01)\n",
    "    \n",
    "        is_rectangle = len(approx) == 4                 # har 4 hjørner/punkter(vertices)\n",
    "        is_reasonable_size = size>4000 and size<100000  # er firkanten en realistisk størrelse\n",
    "    \n",
    "    \n",
    "        if(is_rectangle and is_reasonable_size):        # Prøv at lav figuren til et kort\n",
    "            \n",
    "            card = Card()\n",
    "        \n",
    "            card.contour = c\n",
    "            \n",
    "            card.coords = list(approx.reshape(4,2))\n",
    "            \n",
    "            card.width, card.height = cv2.boundingRect(c)[2:]\n",
    "            \n",
    "            card.set_center()\n",
    "            \n",
    "            card.find_warped_card(og_frame) # Find og extract kortet fra billedet og sæt det i self.warped \n",
    "\n",
    "            card.find_icons()\n",
    "        \n",
    "            if card.validate(): found_cards.append(card) # Hvis kortet er validt. Tilføj til found_cards\n",
    "                \n",
    "    return found_cards\n",
    "\n",
    "def draw_predicted_hand(img, text):\n",
    "\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    TEXT = text\n",
    "    FONT_SIZE = 2\n",
    "    FONT_COLOR = (255, 0, 255)\n",
    "    THICKNESS = 5\n",
    "\n",
    "    ######\n",
    "\n",
    "    # get boundary of this text\n",
    "    text_w, text_h = cv2.getTextSize(TEXT, FONT, FONT_SIZE, THICKNESS)[0]\n",
    "    \n",
    "    img_h, img_w, _ = img.shape\n",
    "    \n",
    "    text_x = int(img_w/2 - text_w/2)\n",
    "    text_y = int(img_h - text_h)\n",
    "\n",
    "    cv2.putText(img, TEXT, (text_x, text_y), FONT, FONT_SIZE, FONT_COLOR, thickness=THICKNESS)\n",
    "\n",
    "    \n",
    "def draw_warps_and_icons_from_cards(cards):\n",
    "    \n",
    "    # [Height,Width,Depth]\n",
    "    s = [1080,1920,3]\n",
    "    \n",
    "    if(len(cards)) == 0: return np.zeros([540,1920,3], dtype=np.uint8)\n",
    "    \n",
    "    \n",
    "    res1 = np.zeros((cards[0].warped_thresh.shape[0],0 ), dtype=np.uint8) #makes an empty 420 x 0 img to make the card in cards loop easier\n",
    "\n",
    "    for card in cards[:5]:\n",
    "        res1 = np.hstack((res1, card.warped_thresh))\n",
    "    \n",
    "    size_scale = s[0] / 2 / res1.shape[0] \n",
    "    res1 = cv2.resize(res1, (0,0), fx=size_scale, fy=size_scale )\n",
    "    res1 = np.hstack((np.zeros((res1.shape[0], s[1]//2-res1.shape[1]), dtype=np.uint8), res1))\n",
    "    res1 = cv2.cvtColor(res1, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "\n",
    "    res2 = np.zeros((540,0,3), dtype=np.uint8)\n",
    "    for card in cards[:5]:\n",
    "        res2 = np.hstack((res2, cv2.resize(card.warped, (192,540))))\n",
    "        \n",
    "    res2 = np.hstack((res2,np.zeros((540, 960 - res2.shape[1], 3), dtype=np.uint8)))\n",
    "    \n",
    "    return np.hstack((res1,res2))\n",
    "#     cv2.imshow(\"warps_thresh\", res1)\n",
    "#     cv2.imshow(\"warps\", res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_frame(frame):\n",
    "    \n",
    "    threshold = 160\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    thresh = cv2.threshold(blur,threshold,255,cv2.THRESH_BINARY)[1]\n",
    "    return thresh\n",
    "\n",
    "def preprocess_frame_clahe(frame):\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
    "    cl1 = clahe.apply(gray)\n",
    "    thresh = cv2.threshold(cl1, 160 ,255,cv2.THRESH_BINARY)[1]\n",
    "    return thresh\n",
    "\n",
    "def preprocess_frame_adap(frame):\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gaus = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 33, 1)\n",
    "    return gaus\n",
    "\n",
    "\n",
    "\n",
    "def find_cards_from_image(frame, model=None): # returns new frame & list of all cards found\n",
    "    \n",
    "    # prepross_frame = preprocess_frame(frame) \n",
    "    # prepross_frame = preprocess_frame_clahe(frame)\n",
    "    prepross_frame = preprocess_frame_adap(frame)\n",
    "    \n",
    "    found_cards = find_cards(frame, prepross_frame) # returns a list of cards from the processed frame\n",
    "    \n",
    "    for card in found_cards:\n",
    "        \n",
    "        card.draw_card_outlines(frame) # outliner kortet\n",
    "        card.draw_text(frame)          # tegner suit osv. over kortet\n",
    "\n",
    "    \n",
    "    ###############################\n",
    "    if model is not None:\n",
    "        \n",
    "        text = str(len(found_cards)) + \"/5 cards found\"\n",
    "\n",
    "        if len(found_cards) >= 5:\n",
    "            nums = [card.num for card in found_cards[:5]]\n",
    "            suits = [card.suit for card in found_cards[:5]]\n",
    "            arr = [[nums + suits]]\n",
    "            \n",
    "            num_dict = {0:\"Nothing\",1:\"Pair\",2:\"Two Pair\",3:\"Three of a kind\",4:\"Straight\",5:\"Flush\",6:\"Full House\",7:\"Four of a kind\",8:\"Straight Flush\",9:\"Royal Flush\"}\n",
    "            \n",
    "            prediction = np.argmax(model.predict_proba(arr))\n",
    "            text = num_dict[prediction]\n",
    "\n",
    "        draw_predicted_hand(frame, text)\n",
    "    ##############################\n",
    "    \n",
    "    warps_img = draw_warps_and_icons_from_cards(found_cards)\n",
    "    res = np.hstack((cv2.cvtColor(prepross_frame,cv2.COLOR_GRAY2RGB),frame))\n",
    "    res = cv2.resize(res, (1920,int(1920*0.5625*0.5)))\n",
    "    res = np.vstack((res,warps_img))\n",
    "    res = cv2.resize(res, (0,0), fx=0.8, fy=0.8)\n",
    "    \n",
    "    return found_cards, res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img_icon(img_path, save_path, suit=True, num=True):\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    prepross_frame = preprocess_frame(img) # processes frame to make it easier to find cards\n",
    "    \n",
    "    found_cards = find_cards(img, prepross_frame) # returns a list of found cards\n",
    "    \n",
    "    if(len(found_cards) == 0): return\n",
    "    \n",
    "    card = found_cards[0] # take first card (there should only be one)\n",
    "    \n",
    "    if suit: cv2.imwrite(save_path, card.suit_img)\n",
    "    if num: cv2.imwrite(save_path, card.num_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_img(img):\n",
    "    img = cv2.imread(img)\n",
    "    model = tf.keras.models.load_model(\"models/hupra_desktop_model_100.h5\")\n",
    "    \n",
    "    cards, preview = find_cards_from_image(img, model)\n",
    "    \n",
    "#     cv2.namedWindow(\"Feed\", cv2.WINDOW_NORMAL)\n",
    "#     cv2.setWindowProperty(\"Feed\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "#     cv2.namedWindow(\"Feed2\", cv2.WINDOW_NORMAL)\n",
    "#     cv2.setWindowProperty(\"Feed2\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    \n",
    "    cv2.imshow(\"Feed\", img)\n",
    "    cv2.imshow(\"Feed2\", preview)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_cam(num=0):\n",
    "    cap = cv2.VideoCapture(num)\n",
    "    \n",
    "    model = tf.keras.models.load_model(\"models/hupra_desktop_model_100.h5\")\n",
    "\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "        ret, frame = cap.read()\n",
    "        cards, preview = find_cards_from_image(frame, model)\n",
    "        \n",
    "        cv2.imshow(\"Feed\", frame)\n",
    "        cv2.imshow(\"Feed2\", preview)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "use_img(\"imgs/img8.jpg\")\n",
    "#use_cam(1)\n",
    "#save_img_icon(\"./pre/clubs.jpg\", \"./delete/this2.jpg\", suit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = {str(x):cv2.imread(\"./test_cards/\"+str(x)+\".jpg\", cv2.IMREAD_GRAYSCALE) for x in range(1,14)}\n",
    "# cv2.imshow(\"Feed\", num_imgs[13])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
